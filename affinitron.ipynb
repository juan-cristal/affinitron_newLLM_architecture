{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinitron: Text-to-Audio Spectral Analysis\n",
    "\n",
    "This notebook analyzes text to build spectral signatures of words and synthesizes them as audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports\n",
    "import re, math\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "plt.rcParams['figure.figsize'] = (10,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple tokenizer\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\",\" \", text)\n",
    "    return [t for t in text.split() if t]\n",
    "\n",
    "# sliding-window co-occurrence\n",
    "def cooccurrence(tokens, window=3):\n",
    "    co = defaultdict(Counter)\n",
    "    for i,w in enumerate(tokens):\n",
    "        left = max(0, i-window)\n",
    "        right = min(len(tokens), i+window+1)\n",
    "        for j in range(left, right):\n",
    "            if j==i: continue\n",
    "            co[w][tokens[j]] += 1\n",
    "    return co\n",
    "\n",
    "corpus_text = '''In recent years the field of artificial intelligence has experienced remarkable growth. Researchers build models that learn from large amounts of text. This text often contains historical, technical, and poetic passages. Understanding how words relate -- not only by frequency but by deeper affinities -- is essential. The Affinitron idea proposes a harmonic organization of knowledge, where grammar, history, and usage create a spectral signature.\n",
    "\n",
    "Consider words like 'apple', 'fruit', 'eat', 'tree', 'garden', 'technology', 'computer', 'algorithm'. In some contexts 'apple' and 'fruit' are strongly related; in others 'apple' might be about the company or a device. Etymology, tempo of adoption, and syntactic roles help reveal the different layers of meaning.\n",
    "\n",
    "We will use this medium-sized toy corpus which is synthetic but varied enough to illustrate structure.\n",
    "'''\n",
    "\n",
    "tokens = tokenize(corpus_text)\n",
    "print('Tokens:', len(tokens))\n",
    "print('Unique tokens:', len(set(tokens)))\n",
    "\n",
    "co = cooccurrence(tokens, window=3)\n",
    "for w,c in list(co.items())[:12]:\n",
    "    print(w, '->', c.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Partial estimation (simple heuristic)\n",
    "rank_to_ratio = {1:1.0, 2:2.0, 3:1.5, 4:1.3333, 5:1.25, 6:1.2}\n",
    "\n",
    "def topk_contexts(co, k=6):\n",
    "    return {w: [x for x,_ in c.most_common(k)] for w,c in co.items()}\n",
    "\n",
    "def estimate_partials(top_contexts, k=3):\n",
    "    out = {}\n",
    "    for w, ctxs in top_contexts.items():\n",
    "        ratios = [rank_to_ratio.get(i+1, 1.0 + 0.05*(i+1)) for i in range(min(k, len(ctxs)))]\n",
    "        amps = [ (k-i)/sum(range(1,k+1)) for i in range(len(ratios)) ]\n",
    "        if not ratios:\n",
    "            ratios = [1.0,2.0,1.5]\n",
    "            amps = [0.6,0.3,0.1]\n",
    "        out[w] = (ratios, amps)\n",
    "    return out\n",
    "\n",
    "top_ctx = topk_contexts(co, k=6)\n",
    "partials = estimate_partials(top_ctx, k=3)\n",
    "print('Example partials for some words:')\n",
    "for w in list(partials.keys())[:8]:\n",
    "    print(w, '->', partials[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Tempo (alpha) estimation using simulated time-slices\n",
    "N_slices = 5\n",
    "slice_len = max(1, len(tokens)//N_slices)\n",
    "slices = [tokens[i*slice_len:(i+1)*slice_len] for i in range(N_slices)]\n",
    "from collections import Counter\n",
    "freq_slices = [Counter(s) for s in slices]\n",
    "\n",
    "def estimate_alpha(word, freq_slices):\n",
    "    svals = np.array([freq_slices[i].get(word, 0) for i in range(len(freq_slices))])\n",
    "    if svals.sum() == 0:\n",
    "        return 1.0\n",
    "    mean = svals.mean(); var = svals.var()\n",
    "    burst = var/(mean+1e-6)\n",
    "    recency_index = np.dot(svals, np.arange(1,len(freq_slices)+1)) / (svals.sum()+1e-6)\n",
    "    alpha = 1.0 + min(3.0, burst*0.5) + (recency_index/(len(freq_slices)*2))\n",
    "    return float(alpha)\n",
    "\n",
    "print('Alpha examples:')\n",
    "for w in ['apple','technology','text','affinitron','fruit','eat']:\n",
    "    print(w, estimate_alpha(w, freq_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Build signatures for top-V words and compute affinity graph\n",
    "from collections import Counter\n",
    "word_counts = Counter(tokens)\n",
    "VOCAB_SIZE = 80\n",
    "vocab = [w for w,_ in word_counts.most_common(VOCAB_SIZE)]\n",
    "\n",
    "def base_pitch(word):\n",
    "    verbs = set(['is','are','build','learn','contain','use','consider','show','reveal','experience','has','have'])\n",
    "    if word in verbs:\n",
    "        return 220.0\n",
    "    if len(word) <= 3:\n",
    "        return 440.0\n",
    "    return 110.0\n",
    "\n",
    "signatures = {}\n",
    "for w in vocab:\n",
    "    ratios, amps = partials.get(w, ([1.0,2.0,1.5],[0.6,0.3,0.1]))\n",
    "    freqs = [base_pitch(w)*r for r in ratios]\n",
    "    alpha = estimate_alpha(w, freq_slices)\n",
    "    signatures[w] = {'freqs': freqs, 'amps': amps, 'alpha': alpha}\n",
    "\n",
    "# affinity functions\n",
    "beta_f = 200.0; beta_alpha = 2.0; w_f=0.7; w_a=0.3\n",
    "\n",
    "def harmonic_overlap(su, sv):\n",
    "    fu = np.array(su['freqs']); fv = np.array(sv['freqs'])\n",
    "    au = np.array(su['amps']); av = np.array(sv['amps'])\n",
    "    sim=0.0; wt=0.0\n",
    "    for i in range(len(fu)):\n",
    "        for j in range(len(fv)):\n",
    "            delta = abs(fu[i]-fv[j]) / max(fu[i], fv[j])\n",
    "            s = math.exp(-beta_f*(delta**2))\n",
    "            w = au[i]*av[j]\n",
    "            sim += w*s; wt += w\n",
    "    return sim/wt if wt>0 else 0.0\n",
    "\n",
    "def tempo_compat(su, sv):\n",
    "    d = math.log(su['alpha']+1e-8) - math.log(sv['alpha']+1e-8)\n",
    "    return math.exp(-beta_alpha*(d**2))\n",
    "\n",
    "V=len(vocab)\n",
    "A = np.zeros((V,V))\n",
    "for i,u in enumerate(vocab):\n",
    "    for j,v in enumerate(vocab):\n",
    "        if i==j: continue\n",
    "        A[i,j] = w_f*harmonic_overlap(signatures[u], signatures[v]) + w_a*tempo_compat(signatures[u], signatures[v])\n",
    "\n",
    "# build graph\n",
    "G = nx.Graph()\n",
    "for w in vocab:\n",
    "    G.add_node(w)\n",
    "threshold = 0.15\n",
    "for i in range(V):\n",
    "    for j in range(i+1,V):\n",
    "        if A[i,j] > threshold:\n",
    "            G.add_edge(vocab[i], vocab[j], weight=float(A[i,j]))\n",
    "print('Graph nodes:', G.number_of_nodes(), 'edges:', G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Visualize graph\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "plt.figure(figsize=(10,8))\n",
    "weights = [G[u][v]['weight']*6 for u,v in G.edges()]\n",
    "nx.draw_networkx_nodes(G, pos, node_size=200, node_color='lightblue')\n",
    "nx.draw_networkx_edges(G, pos, width=weights, alpha=0.7)\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "plt.title('Affinitron affinity graph (toy corpus)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Example path\n",
    "def affinity_path(start, L=6):\n",
    "    path=[start]\n",
    "    cur=start\n",
    "    for _ in range(L-1):\n",
    "        nbrs = sorted(G[cur].items(), key=lambda kv: kv[1]['weight'], reverse=True)\n",
    "        if not nbrs: break\n",
    "        cur=nbrs[0][0]\n",
    "        path.append(cur)\n",
    "    return path\n",
    "\n",
    "print('Path from apple:', affinity_path('apple'))\n",
    "print('Path from technology:', affinity_path('technology'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Synthesis\n",
    "\n",
    "Here we add the ability to synthesize the spectral signatures as audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Audio Synthesis Functions\n",
    "\n",
    "def generate_tone(freqs, amps, duration=1.0, rate=44100):\n",
    "    t = np.linspace(0, duration, int(rate * duration), endpoint=False)\n",
    "    wave = np.zeros_like(t)\n",
    "    \n",
    "    # Normalize amps\n",
    "    amps = np.array(amps)\n",
    "    if amps.sum() > 0:\n",
    "        amps = amps / amps.sum()\n",
    "    \n",
    "    for f, a in zip(freqs, amps):\n",
    "        wave += a * np.sin(2 * np.pi * f * t)\n",
    "    \n",
    "    return wave, rate\n",
    "\n",
    "def apply_envelope(wave, alpha, rate=44100):\n",
    "    # Simple ADSR-like envelope based on alpha (tempo)\n",
    "    # Higher alpha -> faster attack/decay (more percussive)\n",
    "    # Lower alpha -> slower attack/decay (more pad-like)\n",
    "    \n",
    "    duration = len(wave) / rate\n",
    "    t = np.linspace(0, duration, len(wave), endpoint=False)\n",
    "    \n",
    "    # Map alpha to envelope parameters\n",
    "    # alpha ranges roughly 1.0 to 4.0+\n",
    "    attack_time = 0.05 / max(1.0, alpha * 0.5)\n",
    "    decay_time = 0.2 / max(1.0, alpha * 0.5)\n",
    "    \n",
    "    envelope = np.ones_like(wave)\n",
    "    \n",
    "    # Attack\n",
    "    attack_samples = int(attack_time * rate)\n",
    "    if attack_samples > 0:\n",
    "        envelope[:attack_samples] = np.linspace(0, 1, attack_samples)\n",
    "        \n",
    "    # Decay/Release (simplified)\n",
    "    decay_samples = int(decay_time * rate)\n",
    "    if decay_samples > 0 and len(wave) > attack_samples:\n",
    "        remaining = len(wave) - attack_samples\n",
    "        # Exponential decay\n",
    "        decay_curve = np.exp(-np.linspace(0, 5, remaining))\n",
    "        envelope[attack_samples:] = decay_curve\n",
    "        \n",
    "    return wave * envelope\n",
    "\n",
    "def play_signature(word, duration=1.0):\n",
    "    if word not in signatures:\n",
    "        print(f\"Word '{word}' not in signatures.\")\n",
    "        return\n",
    "        \n",
    "    sig = signatures[word]\n",
    "    print(f\"Playing '{word}': Freqs={np.round(sig['freqs'], 1)}, Alpha={sig['alpha']:.2f}\")\n",
    "    \n",
    "    wave, rate = generate_tone(sig['freqs'], sig['amps'], duration=duration)\n",
    "    wave = apply_envelope(wave, sig['alpha'], rate)\n",
    "    \n",
    "    # Normalize to prevent clipping\n",
    "    if np.max(np.abs(wave)) > 0:\n",
    "        wave = wave / np.max(np.abs(wave)) * 0.9\n",
    "        \n",
    "    return ipd.Audio(wave, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Interactive Audio Demo\n",
    "\n",
    "# Play a few words\n",
    "display(play_signature('apple'))\n",
    "display(play_signature('technology'))\n",
    "display(play_signature('is'))\n",
    "\n",
    "# Play a path\n",
    "print(\"\\nPlaying path from 'apple':\")\n",
    "path = affinity_path('apple')\n",
    "for w in path:\n",
    "    display(play_signature(w, duration=0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
